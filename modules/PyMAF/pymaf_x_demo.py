# -*- coding: utf-8 -*-
"""pymaf-x_demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13Iytx1Hb0ZryEwbJdpXBW9ggDxs2Y-tL

## **PyMAF-X: Towards Well-aligned Full-body Model Regression from Monocular Images**
Demo of the original PyTorch based implementation provided here: https://github.com/HongwenZhang/PyMAF

Note
Before running this notebook make sure that your runtime type is 'Python 3 with GPU acceleration'. Go to Edit > Notebook settings > Hardware Accelerator > Select "GPU".

*   ArXiv: https://arxiv.org/abs/2207.06400
*   Paper: https://arxiv.org/pdf/2207.06400.pdf
*   Repo: https://github.com/HongwenZhang/PyMAF
"""

# check if gpu is available
!nvidia-smi

"""## Set up the environment


"""

# Commented out IPython magic to ensure Python compatibility.
# set up code and data for demo
!git clone https://github.com/HongwenZhang/PyMAF.git
# %cd PyMAF
!git checkout smplx

import os
if not os.path.exists('./examples'):
  os.makedirs('./examples')
if not os.path.exists('./data'):
  os.makedirs('./data')

# Commented out IPython magic to ensure Python compatibility.
!wget --no-check-certificate "https://onedrive.live.com/download?cid=4000FF1C757A8D39&resid=4000FF1C757A8D39%212096&authkey=AARry-HzC9EhhSA" -O examples.zip
!wget --no-check-certificate "https://onedrive.live.com/download?cid=4000FF1C757A8D39&resid=4000FF1C757A8D39%212097&authkey=ADY68k1YkFyaUxU" -O data.zip
# %cd examples
!mv ../examples.zip . && unzip -q examples.zip && rm -rf examples.zip
# %cd ../data
!mv ../data.zip . && unzip -q data.zip && rm -rf data.zip
# %cd ..

# PyTorch tested on version 1.9.0
!pip3 install -U torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html
# pytorch3d
!pip3 install -U "git+https://github.com/facebookresearch/pytorch3d.git@stable"
# other packages listed in requirements.txt
!pip3 install -U -r requirements.txt

"""## For an image folder as input:"""

!python3 -m apps.demo_smplx --image_folder examples/coco_images --detection_threshold 0.3 --pretrained_model data/pretrained_model/PyMAF-X_model_checkpoint.pt --misc TRAIN.BHF_MODE full_body MODEL.EVAL_MODE True MODEL.PyMAF.HAND_VIS_TH 0.1

# Display the generated image
from IPython.display import Image
Image(filename='output/coco_images/coco_images_output/COCO_val2014_000000004700.png')

"""## For a video as input:"""

!python3 -m apps.demo_smplx --vid_file examples/dancer.mp4 --pretrained_model data/pretrained_model/PyMAF-X_model_checkpoint.pt --misc TRAIN.BHF_MODE full_body MODEL.EVAL_MODE True MODEL.PyMAF.HAND_VIS_TH 0.1

# Play the generated video
from IPython.display import HTML
from base64 import b64encode

def video(path):
  mp4 = open(path,'rb').read()
  data_url = "data:video/mp4;base64," + b64encode(mp4).decode()
  return HTML('<video width=500 controls loop> <source src="%s" type="video/mp4"></video>' % data_url)

video('output/dancer/dancer_result.mp4')